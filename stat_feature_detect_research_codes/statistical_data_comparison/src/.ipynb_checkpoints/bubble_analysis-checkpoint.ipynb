{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import vtk\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from vtk.util.numpy_support import *\n",
    "import pandas\n",
    "from multiprocessing import Pool\n",
    "from vtk.util import numpy_support\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import linalg as LA\n",
    "from skimage.measure import EllipseModel\n",
    "from matplotlib.patches import Ellipse\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureUtf(s):\n",
    "    try:\n",
    "        if type(s) == unicode:\n",
    "            return s.encode('utf8', 'ignore')\n",
    "    except: \n",
    "        return str(s)\n",
    "\n",
    "def read_vti(filename):\n",
    "    reader = vtk.vtkXMLImageDataReader()\n",
    "    reader.SetFileName(filename)\n",
    "    reader.Update()\n",
    "    return reader.GetOutput()\n",
    "\n",
    "def write_vti(filename,data):\n",
    "    writer = vtk.vtkXMLImageDataWriter()\n",
    "    writer.SetInputData(data)\n",
    "    writer.SetFileName(filename)\n",
    "    writer.Update()\n",
    "    \n",
    "def write_vtu(filename,data):\n",
    "    writer = vtk.vtkXMLUnstructuredGridWriter()\n",
    "    writer.SetInputData(data)\n",
    "    writer.SetFileName(filename)\n",
    "    writer.Update()    \n",
    "    \n",
    "def write_multiblock(filename,data):\n",
    "    writer = vtk.vtkXMLMultiBlockDataWriter()\n",
    "    writer.SetInputData(data)\n",
    "    writer.SetFileName(filename)\n",
    "    writer.Update()    \n",
    "    \n",
    "def compute_bubble_features(fname,confidence_th,size_threshold, tstep, outpath):\n",
    "    \n",
    "    feature_values=[]\n",
    "    \n",
    "    if tstep%10 == 0:\n",
    "        print ('processing time step: ' + str(tstep))\n",
    "        \n",
    "    data = read_vti(fname)\n",
    "    data.GetPointData().SetActiveScalars('feature_similarity')\n",
    "    \n",
    "    gbounds = data.GetBounds()\n",
    "    #print ('Bounds: ' + str(gbounds))\n",
    "    \n",
    "    thresholding = vtk.vtkThreshold()\n",
    "    thresholding.ThresholdByUpper( confidence_th )\n",
    "    thresholding.SetInputData(data)\n",
    "\n",
    "    seg = vtk.vtkConnectivityFilter()\n",
    "    seg.SetInputConnection(thresholding.GetOutputPort())\n",
    "    seg.SetExtractionModeToLargestRegion()\n",
    "    seg.Update()\n",
    "\n",
    "    segmentation = vtk.vtkConnectivityFilter()\n",
    "    segmentation.SetInputConnection(thresholding.GetOutputPort())\n",
    "    segmentation.SetExtractionModeToAllRegions()\n",
    "    segmentation.ColorRegionsOn()\n",
    "    segmentation.Update()\n",
    "\n",
    "    ug = segmentation.GetOutput()\n",
    "    num_segments = segmentation.GetNumberOfExtractedRegions()\n",
    "    \n",
    "    ## compute volumes of each bubble: \n",
    "    ## volume = voxel count\n",
    "    bubble_volumes = np.zeros(num_segments)\n",
    "    for i in range(ug.GetPointData().GetArray('RegionId').GetNumberOfTuples()):\n",
    "        regionId = int(ug.GetPointData().GetArray('RegionId').GetTuple(i)[0])\n",
    "        bubble_volumes[regionId] = bubble_volumes[regionId]+1\n",
    "        \n",
    "    num_valid_features=0\n",
    "    for i in range(num_segments):\n",
    "        if  bubble_volumes[i] > size_threshold:\n",
    "            num_valid_features=num_valid_features+1\n",
    "            \n",
    "    #print (\"Number of valid features: \" + str(num_valid_features))        \n",
    "    \n",
    "    find_max_topmost_xvals=[]\n",
    "    idx=0\n",
    "    for i in range(num_segments):\n",
    "        if  bubble_volumes[i] > size_threshold:\n",
    "            #print ('processing bubble: '+ str(i))\n",
    "            thresholding2 = vtk.vtkThreshold()\n",
    "            thresholding2.SetInputData(ug)\n",
    "            thresholding2.ThresholdBetween(i,i)\n",
    "            thresholding2.Update()\n",
    "\n",
    "            single_feature = thresholding2.GetOutput()\n",
    "            \n",
    "            bounds = single_feature.GetBounds()\n",
    "            aspect_ratio_3d = (bounds[5] - bounds[4])/(bounds[1] - bounds[0])\n",
    "            #print ('aspect ratio: ' + str(aspect_ratio_3d))\n",
    "            \n",
    "            feature_pts = numpy_support.vtk_to_numpy(single_feature.GetPoints().GetData())\n",
    "            \n",
    "            ## compute centroid\n",
    "            x_center = np.mean(feature_pts[:,0])\n",
    "            y_center = np.mean(feature_pts[:,1])\n",
    "            z_center = np.mean(feature_pts[:,2])\n",
    "            \n",
    "            max_x = np.max(feature_pts[:,0])\n",
    "            find_max_topmost_xvals.append([max_x,i,idx])\n",
    "            \n",
    "            ## only x and z components are extracted\n",
    "            feature_pts_2d = feature_pts[:, [0, 2]]\n",
    "            ## Do PCA to project to 2D\n",
    "            pca = PCA(n_components=2)\n",
    "            principalComponents = pca.fit_transform(feature_pts_2d)\n",
    "            eigenvalues = pca.explained_variance_\n",
    "            roundness = np.sqrt(1-((eigenvalues[1]*eigenvalues[1])/(eigenvalues[0]*eigenvalues[0])))\n",
    "            #print ('eigen ratio: ' + str(roundness))\n",
    "            \n",
    "            #print ('volume: ' + str(bubble_volumes[i]))\n",
    "            #print()\n",
    "            \n",
    "            feature_values.append([tstep,i,idx,aspect_ratio_3d,roundness,bubble_volumes[i],x_center,y_center,z_center])\n",
    "            \n",
    "            idx=idx+1\n",
    "            \n",
    "            \n",
    "    ## identify the indices of features which are actually topmost and not desired bubbles\n",
    "    find_max_topmost_xvals = np.asarray(find_max_topmost_xvals)\n",
    "    top_indices=[]\n",
    "    for i in range(len(find_max_topmost_xvals)):\n",
    "        diff = np.abs(gbounds[1]-find_max_topmost_xvals[i,0])\n",
    "        if diff < 0.00005:\n",
    "            top_indices.append(int(find_max_topmost_xvals[i,1]))\n",
    "    \n",
    "    #print ('feature_values len: ' + str(len(feature_values)))\n",
    "    #print (feature_values)\n",
    "    #print ('top indices: ' + str(top_indices))\n",
    "    \n",
    "    ## filter out the top most undesired features and write the file out\n",
    "    mb = vtk.vtkMultiBlockDataSet()\n",
    "    mb.SetNumberOfBlocks(num_valid_features)\n",
    "    idx=0\n",
    "    cnt=0\n",
    "    final_filtered_feature_values=[]\n",
    "    for i in range(num_segments):\n",
    "        \n",
    "        if  bubble_volumes[i] > size_threshold and i not in(top_indices):\n",
    "            thresholding2 = vtk.vtkThreshold()\n",
    "            thresholding2.SetInputData(ug)\n",
    "            thresholding2.ThresholdBetween(i,i)\n",
    "            thresholding2.Update()\n",
    "            single_feature = thresholding2.GetOutput()\n",
    "            mb.SetBlock(idx,single_feature)\n",
    "            \n",
    "            final_filtered_feature_values.append(feature_values[cnt])\n",
    "\n",
    "            idx=idx+1\n",
    "            \n",
    "        if  bubble_volumes[i] > size_threshold:\n",
    "            cnt=cnt+1\n",
    "            \n",
    "    file_name = outpath + 'segmented_' + str(tstep) + '.vtm'\n",
    "    write_multiblock(file_name, mb)\n",
    "        \n",
    "    #print ('final_filtered_feature_values len: ' + str(len(final_filtered_feature_values)))\n",
    "    #print (final_filtered_feature_values)\n",
    "    \n",
    "    return final_filtered_feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "init_time = 75\n",
    "end_time = 78\n",
    "input_path = '../out/mfix_local_grid/'\n",
    "outpath = '../out/mfix_local_grid/segmented_features_1/'\n",
    "confidence_th = 0.9\n",
    "size_threshold = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Run for all timesteps\n",
    "for ii in range(init_time,end_time):\n",
    "    inpfname = input_path + 'slic_compare_' + str(ii) + '.vti'\n",
    "    feature_values_ret = compute_bubble_features(inpfname,confidence_th,size_threshold, ii, outpath)\n",
    "    \n",
    "    outpicklefname = outpath + 'feature_values_' + str(ii) + '.pickle'\n",
    "    pickle.dump(feature_values_ret, open( outpicklefname, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### stack all data to generate csv file for PCP\n",
    "outfname = outpath + 'feature_values.csv'\n",
    "#outfname = '/Users/sdutta/Desktop/feature_values.csv'\n",
    "all_features = np.array([0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "## Reload feature values from pickle file\n",
    "for ii in range(init_time,end_time):    \n",
    "    inpicklefname = outpath + 'feature_values_' + str(ii) + '.pickle'\n",
    "    #print (inpicklefname)\n",
    "    ffname = ensureUtf(inpicklefname)\n",
    "    fname = open(ffname, 'rb')\n",
    "    data = pickle.load(fname, encoding='latin1')\n",
    "    data = np.asarray(data)\n",
    "    all_features = np.vstack((all_features,data))\n",
    "\n",
    "df = pandas.DataFrame(all_features, index=range(all_features.shape[0]),\n",
    "                          columns=range(all_features.shape[1]))\n",
    "\n",
    "all_fnames=[]\n",
    "for i in range(len(all_features)):\n",
    "    fname = 'images/bubble_' + str(int(all_features[i][1])) + '_' + str(int(all_features[i][0])) + '.png'\n",
    "    #all_features[i].append(fname)\n",
    "    all_fnames.append(fname)\n",
    "    \n",
    "## add a last column with filenames\n",
    "df[10] = all_fnames  \n",
    "\n",
    "## write to disk\n",
    "df.to_csv(outfname)\n",
    "# np.savetxt(outfname, all_features, delimiter=',', fmt='%lf')\n",
    "# print ('done generating csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
