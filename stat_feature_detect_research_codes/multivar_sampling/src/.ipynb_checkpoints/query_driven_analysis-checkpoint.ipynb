{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import vtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for isabel\n",
    "raw_data_file1 = '../Data/Isabel_vti/isabel_p_25.vti'\n",
    "raw_data_file2 = '../Data/Isabel_vti/isabel_vel_25.vti'\n",
    "# raw_data_file1 = '../Data/Isabel_vti/isabel_precip_25.vti'\n",
    "# raw_data_file2 = '../Data/Isabel_vti/isabel_qgraup_25.vti'\n",
    "\n",
    "var_name1 = 'Pressure'\n",
    "var_name2 = 'Velocity'\n",
    "percent = 1\n",
    "samp_type = 'random'\n",
    "\n",
    "sampled_file = '../output/isabel_sampled/joint_' + samp_type + '_sampled_isabel_Pressure_Velocity_' + str(percent) + '.vtp'\n",
    "outfile1 = '../output/' + samp_type + '_recon_query_isabel_' + var_name1 + '_' + var_name2 + '_' + str(percent) + '.vtp'\n",
    "outfile3 = '../output/' + 'raw' + '_recon_query_isabel_' + var_name1 + '_' + var_name2 + '.vtp'\n",
    "#outfile2 = '../output/recon_query_isabel_P_VEL.vti'\n",
    "\n",
    "dims = [250,250,50]\n",
    "\n",
    "#pressure\n",
    "var1_th1 = -100\n",
    "var1_th2 = -5000\n",
    "\n",
    "#Velocity\n",
    "var2_th1 = 10\n",
    "var2_th2 = 75\n",
    "\n",
    "# #qva\n",
    "# var2_th1 = 0.017\n",
    "# var2_th2 = 1.0\n",
    "\n",
    "# #precip\n",
    "# var1_th1 = 0.00069\n",
    "# var1_th2 = 1\n",
    "\n",
    "# #QGraup\n",
    "# var2_th1 = 0.00069\n",
    "# var2_th2 = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## for asteroid\n",
    "# raw_data_file1 = '../Data/Asteroid/tev.vti'\n",
    "# raw_data_file2 = '../Data/Asteroid/v02.vti'\n",
    "\n",
    "# var_name1 = 'tev'\n",
    "# var_name2 = 'v02'\n",
    "# percent = 9\n",
    "# samp_type = 'random'\n",
    "\n",
    "# sampled_file = '../output/asteroid_sampled/joint_' + samp_type + '_sampled_asteroid_tev_v02_' + str(percent) + '.vtp'\n",
    "# outfile1 = '../output/' + samp_type + '_recon_query_asteroid_' + var_name1 + '_' + var_name2 + '_' + str(percent) + '.vtp'\n",
    "# outfile3 = '../output/' + 'raw' + '_recon_query_asteroid_' + var_name1 + '_' + var_name2 + '.vtp'\n",
    "\n",
    "# dims = [300,300,300]\n",
    "\n",
    "# # ## Query 1\n",
    "# # #tev\n",
    "# # var1_th1 = 0.13\n",
    "# # var1_th2 = 0.5\n",
    "\n",
    "# # #v02\n",
    "# # var2_th1 = 0.45\n",
    "# # var2_th2 = 1.0\n",
    "\n",
    "\n",
    "# # ## Query 2\n",
    "# #tev\n",
    "# var1_th1 = 0.1\n",
    "# var1_th2 = 0.3\n",
    "\n",
    "# #v02\n",
    "# var2_th1 = 0.01\n",
    "# var2_th2 = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## for Combustion\n",
    "# raw_data_file1 = '../Data/Combustion/combustion_mixfrac.vti'\n",
    "# raw_data_file2 = '../Data/Combustion/combustion_Y_OH.vti'\n",
    "\n",
    "# var_name1 = 'mixfrac'\n",
    "# var_name2 = 'Y_OH'\n",
    "# percent = 1\n",
    "# samp_type = 'pmi'\n",
    "\n",
    "# sampled_file = '../output/combustion_sampled/joint_' + samp_type + '_sampled_combustion_mixfrac_Y_OH_' + str(percent) + '.vtp'\n",
    "# outfile1 = '../output/' + samp_type + '_recon_query_combustion_' + var_name1 + '_' + var_name2 + '_' + str(percent) + '.vtp'\n",
    "# outfile3 = '../output/' + 'raw' + '_recon_query_combustion_' + var_name1 + '_' + var_name2 + '.vtp'\n",
    "\n",
    "# dims = [240,360,60]\n",
    "\n",
    "# ## Query 1\n",
    "# # #mixfrac\n",
    "# # var1_th1 = 0.3\n",
    "# # var1_th2 = 0.7\n",
    "\n",
    "# # #Y_OH\n",
    "# # var2_th1 = 0.0006\n",
    "# # var2_th2 = 0.1\n",
    "\n",
    "\n",
    "# ## Query 2\n",
    "# #mixfrac\n",
    "# var1_th1 = 0.7\n",
    "# var1_th2 = 1.0\n",
    "\n",
    "# #Y_OH\n",
    "# var2_th1 = 0.0005\n",
    "# var2_th2 = 0.0019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load raw data\n",
    "reader1 = vtk.vtkXMLImageDataReader()\n",
    "reader1.SetFileName(raw_data_file1)\n",
    "reader1.Update()\n",
    "raw_data1 = reader1.GetOutput()\n",
    "\n",
    "reader2 = vtk.vtkXMLImageDataReader()\n",
    "reader2.SetFileName(raw_data_file2)\n",
    "reader2.Update()\n",
    "raw_data2 = reader2.GetOutput()\n",
    "\n",
    "extent = raw_data1.GetExtent()\n",
    "spacing = raw_data1.GetSpacing()\n",
    "origin = raw_data1.GetOrigin()\n",
    "dims = raw_data1.GetDimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load sampled data\n",
    "reader3 = vtk.vtkXMLPolyDataReader()\n",
    "reader3.SetFileName(sampled_file)\n",
    "reader3.Update()\n",
    "sampled_pts = reader3.GetOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_3d_to_1d_map(x,y,z,dimx,dimy,dimz):\n",
    "    index = x + dimx*(y+dimy*z)\n",
    "    return index\n",
    "\n",
    "def getDist(pts1,pts2):\n",
    "    dist = (pts1[0]-pts2[0])*(pts1[0]-pts2[0]) + (pts1[1]-pts2[1])*(pts1[1]-pts2[1]) + (pts1[2]-pts2[2])*(pts1[2]-pts2[2])\n",
    "    return dist\n",
    "\n",
    "def emd(cdf1,cdf2):\n",
    "    numBins = np.shape(cdf1)[0]\n",
    "\n",
    "    emd=0\n",
    "    for i in range(numBins):\n",
    "        emd = emd + abs(cdf1[i] - cdf2[i])\n",
    "        \n",
    "    return emd\n",
    "\n",
    "def jaccard_sim(a,b):\n",
    "    inter = a.intersection(b)\n",
    "    uni = a.union(b)\n",
    "    return len(inter)/float(len(uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## query performed on raw data\n",
    "query_pts_raw = vtk.vtkPoints()\n",
    "query_pts_physical_raw = vtk.vtkPoints()\n",
    "query_arr_raw1 = vtk.vtkDoubleArray()\n",
    "query_arr_raw1.SetName(var_name1)\n",
    "query_arr_raw2 = vtk.vtkDoubleArray()\n",
    "query_arr_raw2.SetName(var_name2)\n",
    "\n",
    "for i in range(dims[0]*dims[1]*dims[2]):\n",
    "    val1 = raw_data1.GetPointData().GetArray(var_name1).GetTuple1(i)\n",
    "    val2 = raw_data2.GetPointData().GetArray(var_name2).GetTuple1(i)\n",
    "    \n",
    "    if val1 <= var1_th1 and val1 >= var1_th2 and val2 >= var2_th1 and val2 <= var2_th2:   ## for isabel pressure\n",
    "    #if val1 >= var1_th1 and val1 <= var1_th2 and val2 >= var2_th1 and val2 <= var2_th2:   ## for others \n",
    "        pts = raw_data1.GetPoint(i)        \n",
    "        query_arr_raw1.InsertNextTuple1(val1)   \n",
    "        query_arr_raw2.InsertNextTuple1(val2)\n",
    "        query_pts_physical_raw.InsertNextPoint(pts)\n",
    "        \n",
    "print (query_pts_physical_raw.GetNumberOfPoints())  \n",
    "\n",
    "pdata_raw = vtk.vtkPolyData()\n",
    "pdata_raw.SetPoints(query_pts_physical_raw)\n",
    "pdata_raw.GetPointData().AddArray(query_arr_raw1)\n",
    "pdata_raw.GetPointData().AddArray(query_arr_raw2)\n",
    "\n",
    "# writer1 = vtk.vtkXMLPolyDataWriter()\n",
    "# writer1.SetInputData(pdata_raw)\n",
    "# writer1.SetFileName(outfile3)\n",
    "# writer1.Write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Query sampled data\n",
    "\n",
    "## create new image data\n",
    "new_data = vtk.vtkImageData()\n",
    "new_data.SetDimensions(dims)\n",
    "new_data.SetSpacing(spacing)\n",
    "new_data.SetOrigin(origin)\n",
    "\n",
    "## create point arrays\n",
    "query_pts = vtk.vtkPoints()\n",
    "query_pts_physical = vtk.vtkPoints()\n",
    "\n",
    "query_arr1 = vtk.vtkDoubleArray()\n",
    "query_arr1.SetName(var_name1)\n",
    "query_arr2 = vtk.vtkDoubleArray()\n",
    "query_arr2.SetName(var_name2)\n",
    "\n",
    "query_arr_new = vtk.vtkDoubleArray()\n",
    "query_arr_new.SetName('lookUp')\n",
    "query_arr_new.SetNumberOfTuples(dims[0]*dims[1]*dims[2])\n",
    "\n",
    "query_arr_new1 = vtk.vtkDoubleArray()\n",
    "query_arr_new1.SetName(var_name1)\n",
    "query_arr_new1.SetNumberOfTuples(dims[0]*dims[1]*dims[2])\n",
    "\n",
    "query_arr_new2 = vtk.vtkDoubleArray()\n",
    "query_arr_new2.SetName(var_name2)\n",
    "query_arr_new2.SetNumberOfTuples(dims[0]*dims[1]*dims[2])\n",
    "\n",
    "for i in range(dims[0]*dims[1]*dims[2]):\n",
    "    query_arr_new1.SetTuple1(i,0.0)\n",
    "    query_arr_new2.SetTuple1(i,0.0)\n",
    "    query_arr_new.SetTuple1(i,0.0)\n",
    "\n",
    "for i in range(sampled_pts.GetNumberOfPoints()):\n",
    "    val1 = sampled_pts.GetPointData().GetArray(var_name1).GetTuple1(i)\n",
    "    val2 = sampled_pts.GetPointData().GetArray(var_name2).GetTuple1(i)\n",
    "    \n",
    "    if val1 <= var1_th1 and val1 >= var1_th2 and val2 >= var2_th1 and val2 <= var2_th2:   ## for isabel pressure\n",
    "    #if val1 >= var1_th1 and val1 <= var1_th2 and val2 >= var2_th1 and val2 <= var2_th2:   ## for others    \n",
    "        pts = sampled_pts.GetPoint(i)        \n",
    "        ii = int((pts[0] - origin[0])/spacing[0] + 0.5)\n",
    "        jj = int((pts[1] - origin[1])/spacing[1] + 0.5)\n",
    "        kk = int((pts[2] - origin[2])/spacing[2] + 0.5)\n",
    "        query_pts.InsertNextPoint([ii,jj,kk])\n",
    "        query_arr1.InsertNextTuple1(val1)   \n",
    "        query_arr2.InsertNextTuple1(val2)\n",
    "        query_pts_physical.InsertNextPoint(pts)\n",
    "        \n",
    "        index = compute_3d_to_1d_map(ii,jj,kk,dims[0],dims[1],dims[2])\n",
    "        \n",
    "        query_arr_new.SetTuple1(index,1)\n",
    "        query_arr_new1.SetTuple1(index,val1)\n",
    "        query_arr_new2.SetTuple1(index,val2)\n",
    "        \n",
    "print query_pts.GetNumberOfPoints()  \n",
    "\n",
    "pdata = vtk.vtkPolyData()\n",
    "pdata.SetPoints(query_pts_physical)\n",
    "pdata.GetPointData().AddArray(query_arr1)\n",
    "pdata.GetPointData().AddArray(query_arr2)\n",
    "\n",
    "# writer1 = vtk.vtkXMLPolyDataWriter()\n",
    "# writer1.SetInputData(pdata)\n",
    "# writer1.SetFileName(outfile1)\n",
    "# writer1.Write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_raw_pts = pdata_raw.GetNumberOfPoints()\n",
    "num_query_pts = pdata.GetNumberOfPoints()\n",
    "\n",
    "raw_set = set()\n",
    "query_set = set()\n",
    "\n",
    "raw_pts_ids = np.zeros(num_raw_pts)\n",
    "query_pts_ids = np.zeros(num_query_pts)\n",
    "\n",
    "pts_query_raw = np.zeros((num_raw_pts,3))\n",
    "for i in range(num_raw_pts):\n",
    "    pts = pdata_raw.GetPoint(i)\n",
    "    ## get the computational loc \n",
    "    ii = int((pts[0] - origin[0])/spacing[0] + 0.5)\n",
    "    jj = int((pts[1] - origin[1])/spacing[1] + 0.5)\n",
    "    kk = int((pts[2] - origin[2])/spacing[2] + 0.5)\n",
    "    \n",
    "    pts_query_raw[i][0] = ii\n",
    "    pts_query_raw[i][1] = jj\n",
    "    pts_query_raw[i][2] = kk\n",
    "    \n",
    "    idx = compute_3d_to_1d_map(ii,jj,kk,dims[0],dims[1],dims[2])\n",
    "    raw_pts_ids[i] = idx\n",
    "    raw_set.add(idx)\n",
    "\n",
    "\n",
    "pts_query = np.zeros((num_query_pts,3))\n",
    "for i in range(num_query_pts):\n",
    "    pts = pdata.GetPoint(i)\n",
    "    \n",
    "    ## get the computational loc \n",
    "    ii = int((pts[0] - origin[0])/spacing[0] + 0.5)\n",
    "    jj = int((pts[1] - origin[1])/spacing[1] + 0.5)\n",
    "    kk = int((pts[2] - origin[2])/spacing[2] + 0.5)\n",
    "    \n",
    "    pts_query[i][0] = ii\n",
    "    pts_query[i][1] = jj\n",
    "    pts_query[i][2] = kk\n",
    "    \n",
    "    idx = compute_3d_to_1d_map(ii,jj,kk,dims[0],dims[1],dims[2])\n",
    "    query_pts_ids[i] = idx\n",
    "    query_set.add(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMD is: 3.3611436800000027\n"
     ]
    }
   ],
   "source": [
    "numBins = 128\n",
    "hist1 = np.zeros(numBins)\n",
    "hist2 = np.zeros(numBins)\n",
    "cdf1 = np.zeros(numBins)\n",
    "cdf2 = np.zeros(numBins)\n",
    "\n",
    "minval = 0\n",
    "maxval = dims[0]*dims[1]*dims[2]\n",
    "   \n",
    "for i in range(num_raw_pts):\n",
    "    binid = int(((raw_pts_ids[i] - minval)/float(maxval-minval))*(numBins-1))\n",
    "    hist1[binid] += 1 \n",
    "    \n",
    "hist1 = hist1/float(maxval)    \n",
    "\n",
    "for i in range(numBins):\n",
    "    if i ==0:\n",
    "        cdf1[i] = hist1[i]\n",
    "    else:\n",
    "        cdf1[i] = cdf1[i-1] + hist1[i]\n",
    "\n",
    "for i in range(num_query_pts):\n",
    "    binid = int(((query_pts_ids[i] - minval)/float(maxval-minval))*(numBins-1))\n",
    "    hist2[binid] += 1     \n",
    "    \n",
    "hist2 = hist2/float(maxval)  \n",
    "\n",
    "for i in range(numBins):\n",
    "    if i ==0:\n",
    "        cdf2[i] = hist2[i]\n",
    "    else:\n",
    "        cdf2[i] = cdf2[i-1] + hist2[i]    \n",
    "         \n",
    "print 'EMD is: ' + str(emd(cdf1,cdf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard: 0.00961818482342\n"
     ]
    }
   ],
   "source": [
    "## compute jaccard similarity\n",
    "print 'jaccard: ' + str(jaccard_sim(raw_set,query_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
